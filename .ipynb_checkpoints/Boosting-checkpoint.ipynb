{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is an ensemble method that aggregates a number of weak models to create one strong model.\n",
    "By weak model, we mean a model where its predictions are only slightly better than random guessing. So for instance, if it's a binary outcome, then we roughly have a 50% chance of getting the right answer just by guessing.\n",
    "A strong model is one where its predictions are very strongly correlated with the actual outcome.\n",
    "Boosting iteratively builds weak models where each one learns from the previous model's mistakes. So in the end, as a whole, it has constantly improved by learning from its own mistakes to generate really powerful predictions. \n",
    "So by the end, you have n relatively weak models, but as a whole, they have learned from the mistakes of all prior iterations, so together they represent a very strong model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Boosting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(GradientBoostingClassifier())\n",
    "print(GradientBoostingRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are mostly interested in parameter n_estimators(number of trees), max_depth(maximum depth of each individual tree) and learning_rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features = pd.read_csv('./dataset/train_features.csv')\n",
    "tr_labels = pd.read_csv('./dataset/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check our model accuracy for different values of hyperparameters max_depth, n_estimators and learning_rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to print results of model beautifully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('Best params: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model using grid search cv and getting best estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.811 (+/-0.117) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.811 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.83 (+/-0.074) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.841 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.82 (+/-0.051) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.818 (+/-0.043) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.826 (+/-0.047) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.817 (+/-0.049) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.816 (+/-0.038) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.803 (+/-0.021) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.803 (+/-0.059) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.798 (+/-0.042) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.794 (+/-0.048) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.815 (+/-0.119) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.818 (+/-0.111) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.828 (+/-0.092) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.813 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.841 (+/-0.07) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.826 (+/-0.032) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.809 (+/-0.04) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.817 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.818 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.802 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.8 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.822 (+/-0.051) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.796 (+/-0.026) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.798 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.798 (+/-0.028) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.798 (+/-0.04) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.792 (+/-0.03) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.788 (+/-0.019) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.794 (+/-0.039) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.818 (+/-0.099) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.832 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.826 (+/-0.077) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.822 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.82 (+/-0.061) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.792 (+/-0.042) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.79 (+/-0.038) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.788 (+/-0.038) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.79 (+/-0.028) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.794 (+/-0.048) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.788 (+/-0.041) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.794 (+/-0.037) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.787 (+/-0.038) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.794 (+/-0.057) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.794 (+/-0.043) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.783 (+/-0.027) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.786 (+/-0.04) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.788 (+/-0.043) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.785 (+/-0.032) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.788 (+/-0.059) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.492 (+/-0.342) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.438 (+/-0.304) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.404 (+/-0.218) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.402 (+/-0.213) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.644 (+/-0.19) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.597 (+/-0.184) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.605 (+/-0.167) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.62 (+/-0.172) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.693 (+/-0.105) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.693 (+/-0.1) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.706 (+/-0.116) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.71 (+/-0.123) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.356 (+/-0.186) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.344 (+/-0.178) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.344 (+/-0.179) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.354 (+/-0.183) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.552 (+/-0.11) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.56 (+/-0.116) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.562 (+/-0.113) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.59 (+/-0.096) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.672 (+/-0.059) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.655 (+/-0.057) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.672 (+/-0.066) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.674 (+/-0.09) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out best pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/Boosting_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, './models/Boosting_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
